import os, io, math, asyncio, datetime as dt
import requests
import streamlit as st
from urllib.parse import urlencode, quote

# -------------------------
# ê¸°ë³¸ ì„¤ì •
# -------------------------
st.set_page_config(page_title="Shorts Asset Finder", layout="wide")

st.title("ğŸ¬ Shorts Asset Finder")
st.caption("ì •ì¹˜Â·ì‹œì‚¬ ì´ìŠˆìš© ì‚¬ì§„/ì˜ìƒ ìë™ ìˆ˜ì§‘ (ë¼ì´ì„ ìŠ¤Â·ì¶œì²˜ ìë™ê¸°ë¡)")

# ì‚¬ì´ë“œë°”: API í‚¤/ì˜µì…˜
with st.sidebar:
    st.header("ğŸ” API Keys (st.secrets ê¶Œì¥)")
    PEXELS_KEY   = st.text_input("Pexels API Key",  value=st.secrets.get("PEXELS_KEY", ""), type="password")
    PIXABAY_KEY  = st.text_input("Pixabay API Key", value=st.secrets.get("PIXABAY_KEY", ""), type="password")
    YT_KEY       = st.text_input("YouTube Data API Key (ì„ íƒ)", value=st.secrets.get("YOUTUBE_API_KEY", ""), type="password")

    st.header("âš™ï¸ ê²€ìƒ‰ ì˜µì…˜")
    query = st.text_input("ê²€ìƒ‰ì–´(ì´ìŠˆ/ì¸ë¬¼/ì¥ë©´)", placeholder="ì˜ˆ: êµ­íšŒ ë³¸íšŒì˜, ìœ¤ì„ì—´, ë¯¸ ëŒ€ì„  í† ë¡ , protest crowd")
    media_types = st.multiselect("íƒ€ì…", ["photo","video"], default=["photo","video"])
    is_person   = st.checkbox("ì¸ë¬¼(ì •ì¹˜ì¸) P18 ìš°ì„  íƒìƒ‰", value=True)
    max_results = st.slider("ìµœëŒ€ ê²°ê³¼/ì†ŒìŠ¤", 5, 50, 20, step=5)
    want_vertical = st.checkbox("ì„¸ë¡œ(9:16) ìš°ì„ ", value=True)
    safe_search = st.checkbox("ì„¸ì´í”„ì„œì¹˜(ê°€ëŠ¥í•œ ì†ŒìŠ¤ë§Œ)", value=True)
    cc_only_openverse = st.selectbox("Openverse ë¼ì´ì„ ìŠ¤", ["any","cc0","by","by-sa","by-nc","by-nd","by-nc-sa","by-nc-nd"], index=0)
    use_sources = st.multiselect("ì‚¬ìš© ì†ŒìŠ¤", ["Wikidata/Commons(P18)","Pexels","Pixabay","Openverse","YouTube(CC-BY ë©”íƒ€ë§Œ)"],
                                 default=["Wikidata/Commons(P18)","Pexels","Pixabay","Openverse","YouTube(CC-BY ë©”íƒ€ë§Œ)"])

def aspect_score(w,h, prefer_vertical=True):
    if not w or not h: return 0
    r = w / h
    target = 9/16 if prefer_vertical else 16/9
    return 1 - min(1, abs(r - target) / target)

def license_block(item):
    return f"**License**: {item.get('license','?')}  \n**Attribution**: {item.get('attribution','')}  \n**Source**: {item.get('source_url','')}"

# -------------------------
# ê° ì†ŒìŠ¤ë³„ ê²€ìƒ‰ í•¨ìˆ˜
# -------------------------
def search_pexels(q, per_page=20, orientation=None):
    if not PEXELS_KEY: return []
    url = "https://api.pexels.com/v1/search"
    headers = {"Authorization": PEXELS_KEY}
    params = {"query": q, "per_page": per_page}
    if orientation: params["orientation"] = orientation
    r = requests.get(url, headers=headers, params=params, timeout=20)
    r.raise_for_status()
    out=[]
    for p in r.json().get("photos", []):
        out.append({
            "provider":"pexels","type":"photo",
            "preview": p["src"]["medium"], "download": p["src"]["original"],
            "width": p.get("width"), "height": p.get("height"),
            "license": "Pexels License",
            "attribution": f'{p.get("photographer","")} (Pexels)',
            "source_url": p.get("url")
        })
    # ë¹„ë””ì˜¤ë„ ì›í•˜ë©´ ë¹„ë””ì˜¤ API
    if "video" in media_types:
        vr = requests.get("https://api.pexels.com/videos/search", headers=headers,
                          params={"query": q, "per_page": per_page}, timeout=20)
        if vr.ok:
            for v in vr.json().get("videos", []):
                files = v.get("video_files", [])
                best = max(files, key=lambda f: f.get("width",0)*f.get("height",0)) if files else {}
                out.append({
                    "provider":"pexels","type":"video",
                    "preview": v.get("image"), "download": best.get("link"),
                    "width": best.get("width"), "height": best.get("height"),
                    "duration": v.get("duration"),
                    "license": "Pexels License",
                    "attribution": f'Pexels Video by {v.get("user",{}).get("name","")}',
                    "source_url": v.get("url")
                })
    return out

def search_pixabay(q, per_page=20, safesearch=True):
    if not PIXABAY_KEY: return []
    base = "https://pixabay.com/api/"
    par = {"key": PIXABAY_KEY, "q": q, "per_page": per_page, "safesearch": str(safesearch).lower()}
    r = requests.get(base, params=par, timeout=20)
    out=[]
    if r.ok:
        for h in r.json().get("hits",[]):
            out.append({
                "provider":"pixabay","type":"photo",
                "preview": h.get("previewURL"), "download": h.get("largeImageURL"),
                "width": h.get("imageWidth"), "height": h.get("imageHeight"),
                "license": "Pixabay Content License",
                "attribution": f'{h.get("user","")} (Pixabay)',
                "source_url": h.get("pageURL")
            })
    if "video" in media_types:
        vr = requests.get("https://pixabay.com/api/videos/", params=par, timeout=20)
        if vr.ok:
            for h in vr.json().get("hits",[]):
                vids = h.get("videos",{})
                best = vids.get("large") or vids.get("medium") or vids.get("small") or {}
                out.append({
                    "provider":"pixabay","type":"video",
                    "preview": h.get("picture_id") and f"https://i.vimeocdn.com/video/{h['picture_id']}_640x360.jpg",
                    "download": best.get("url"),
                    "width": best.get("width"), "height": best.get("height"),
                    "duration": h.get("duration"),
                    "license": "Pixabay Content License",
                    "attribution": f'{h.get("user","")} (Pixabay)',
                    "source_url": h.get("pageURL")
                })
    return out

def search_openverse(q, per_page=20, license_type="any"):
    url = "https://api.openverse.org/v1/images/"
    params = {"q": q, "page_size": per_page}
    if license_type != "any":
        params["license_type"] = license_type
    r = requests.get(url, params=params, timeout=20)
    out=[]
    if r.ok:
        for rj in r.json().get("results",[]):
            out.append({
                "provider":"openverse","type":"photo",
                "preview": rj.get("thumbnail"), "download": rj.get("url"),
                "width": rj.get("width"), "height": rj.get("height"),
                "license": rj.get("license", "").upper(),
                "attribution": rj.get("attribution","Openverse"),
                "source_url": rj.get("foreign_landing_url") or rj.get("url")
            })
    return out

def wikidata_p18_image(name):
    """ì´ë¦„ìœ¼ë¡œ ìœ„í‚¤ë°ì´í„° ê²€ìƒ‰â†’P18 íŒŒì¼â†’Commons ì›ë³¸/ë¼ì´ì„ ìŠ¤ ë©”íƒ€"""
    # 1) ì—”í„°í‹° ê²€ìƒ‰
    s = requests.get("https://www.wikidata.org/w/api.php",
                     params={"action":"wbsearchentities","search":name,"language":"ko","format":"json","limit":1}, timeout=20)
    if not s.ok or not s.json().get("search"): return None
    qid = s.json()["search"][0]["id"]
    # 2) ì—”í„°í‹° ìƒì„¸
    e = requests.get(f"https://www.wikidata.org/wiki/Special:EntityData/{qid}.json", timeout=20)
    ent = e.json()["entities"][qid]
    claims = ent.get("claims",{})
    if "P18" not in claims: return None
    filename = claims["P18"][0]["mainsnak"]["datavalue"]["value"]  # e.g., "Yoon Suk-yeol in 2022.jpg"
    # 3) Commons ë©”íƒ€
    title = f"File:{filename}"
    c = requests.get("https://commons.wikimedia.org/w/api.php",
                     params={"action":"query","prop":"imageinfo","iiprop":"url|extmetadata","titles":title,"format":"json"}, timeout=20)
    pages = c.json().get("query",{}).get("pages",{})
    if not pages: return None
    page = next(iter(pages.values()))
    ii = (page.get("imageinfo") or [{}])[0]
    meta = ii.get("extmetadata",{})
    return {
        "provider":"wikimedia","type":"photo",
        "preview": ii.get("url"), "download": ii.get("url"),
        "width": None, "height": None,
        "license": meta.get("LicenseShortName",{}).get("value",""),
        "attribution": meta.get("Artist",{}).get("value","").strip() or "Wikimedia Commons",
        "source_url": f"https://commons.wikimedia.org/wiki/{title}"
    }

def search_youtube_cc(q, per_page=20):
    if not YT_KEY: return []
    params = {
        "part":"snippet","q":q,"type":"video","maxResults":min(per_page, 50),
        "videoLicense":"creativeCommon","safeSearch":"moderate"
    }
    r = requests.get("https://www.googleapis.com/youtube/v3/search", params={**params,"key":YT_KEY}, timeout=20)
    out=[]
    if r.ok:
        for item in r.json().get("items",[]):
            vid = item["id"]["videoId"]
            url = f"https://www.youtube.com/watch?v={vid}"
            thumb = item["snippet"]["thumbnails"]["medium"]["url"]
            out.append({
                "provider":"youtube","type":"video",
                "preview": thumb, "download": None,  # YouTubeëŠ” ë‹¤ìš´ë¡œë“œ ê¸ˆì§€(ë§í¬ë§Œ)
                "width": None, "height": None,
                "license": "CC-BY (YouTube setting)",  # ì‹¤ì œ CC-BY ê³ ì§€
                "attribution": item["snippet"].get("channelTitle","YouTube"),
                "source_url": url
            })
    return out

# -------------------------
# ì‹¤í–‰
# -------------------------
if st.button("ê²€ìƒ‰ ì‹¤í–‰", use_container_width=True) and query.strip():
    items = []

    # ìœ„í‚¤ë°ì´í„°/ì»¤ë¨¼ì¦ˆ(P18): ì¸ë¬¼ ì‚¬ì§„
    if is_person and "Wikidata/Commons(P18)" in use_sources:
        wd = wikidata_p18_image(query)
        if wd: items.append(wd)

    # Pexels
    if "Pexels" in use_sources and ("photo" in media_types or "video" in media_types):
        items += search_pexels(query, per_page=max_results, orientation="portrait" if want_vertical else None)

    # Pixabay
    if "Pixabay" in use_sources and ("photo" in media_types or "video" in media_types):
        items += search_pixabay(query, per_page=max_results, safesearch=safe_search)

    # Openverse
    if "Openverse" in use_sources and "photo" in media_types:
        items += search_openverse(query, per_page=max_results, license_type=cc_only_openverse)

    # YouTube (CC-BY ë©”íƒ€ë§Œ, ë§í¬ ì œê³µ)
    if "YouTube(CC-BY ë©”íƒ€ë§Œ)" in use_sources and "video" in media_types:
        items += search_youtube_cc(query, per_page=max_results)

    # ì ìˆ˜(ì„¸ë¡œìš°ì„  + ì‹ ë¢°ë„ ê°„ë‹¨ ê°€ì¤‘)
    for it in items:
        it["score"] = 0.6*aspect_score(it.get("width"), it.get("height"), prefer_vertical=want_vertical) + \
                      0.4*(1 if it["provider"] in ["wikimedia","openverse","pexels","pixabay"] else 0.7)

    # ì¤‘ë³µ ì œê±°(ì†ŒìŠ¤ URL ê¸°ì¤€)
    dedup = {}
    for it in items:
        k = (it["provider"], it.get("source_url") or it.get("download") or it.get("preview"))
        if k not in dedup: dedup[k] = it
    items = sorted(dedup.values(), key=lambda x: x["score"], reverse=True)

    st.write(f"ì´ {len(items)}ê°œ ê²°ê³¼")
    cols = st.columns(3)
    picks = []
    for i, it in enumerate(items):
        with cols[i%3]:
            st.markdown(f"**{it['provider']} Â· {it['type']}**  \nScore: {it['score']:.2f}")
            if it["type"]=="photo":
                st.image(it["preview"], use_column_width=True)
            else:
                st.image(it["preview"], use_column_width=True)  # ì¸ë„¤ì¼
            st.markdown(license_block(it))
            ck = st.checkbox("ì„ íƒ", key=f"pick_{i}")
            if ck:
                picks.append(it)

    if picks:
        st.subheader("âœ… ì„ íƒí•œ í•­ëª©")
        st.download_button("ë©”íƒ€ë°ì´í„° CSV ë‚´ë³´ë‚´ê¸°",
                           data="provider,type,preview,download,width,height,duration,license,attribution,source_url\n" +
                                "\n".join([",".join([str(it.get(k,"")).replace(","," ") for k in
                                 ["provider","type","preview","download","width","height","duration","license","attribution","source_url"]]) for it in picks]),
                           file_name=f"assets_{dt.datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                           mime="text/csv")
        # í—ˆìš© ì†ŒìŠ¤ë§Œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ì•ˆë‚´
        st.info("ğŸ“¥ Pexels/Pixabay/Wikimedia/OpenverseëŠ” ë‹¤ìš´ë¡œë“œ ì‚¬ìš© ê°€ëŠ¥(ê° ë¼ì´ì„ ìŠ¤ ì¡°ê±´ ì¤€ìˆ˜). YouTubeëŠ” ë§í¬ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.")
else:
    st.info("ì¢Œì¸¡ì—ì„œ í‚¤/ì˜µì…˜ì„ ì„¤ì •í•˜ê³  â€˜ê²€ìƒ‰ ì‹¤í–‰â€™ì„ ëˆŒëŸ¬ë³´ì„¸ìš”!")
